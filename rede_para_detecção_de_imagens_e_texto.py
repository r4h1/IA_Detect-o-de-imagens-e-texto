# -*- coding: utf-8 -*-
"""Rede para detecção de imagens e texto.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N-cRxsu5HG9-sqrvqpj0CjD-MLaNbBsU
"""

# Install espeak first, so the pyttsx3 can find it.
!apt-get install -y espeak

# Instalar pacotes, modulos, dependencias e frameworks.
!pip install ultralytics opencv-python-headless pillow easyocr pyttsx3

!pip install gradio

from IPython.display import display, Javascript
from google.colab.output import eval_js
import cv2
import numpy as np
import base64

# JavaScript function to capture webcam frames
def capture_webcam():
    js = Javascript('''
        async function captureWebcam() {
            const video = document.createElement('video');
            video.style.display = 'none';
            document.body.appendChild(video);

            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
            await new Promise((resolve) => (video.onloadedmetadata = resolve));
            video.play();

            // Create canvas to capture frames
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const ctx = canvas.getContext('2d');

            while (true) {
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                const data = canvas.toDataURL('image/jpeg');
                google.colab.kernel.invokeFunction('notebook.captureFrame', [data], {});
                await new Promise(resolve => setTimeout(resolve, 100));
            }
        }
        captureWebcam();
    ''')
    display(js)

# Function to decode base64 image from JavaScript
def decode_image(image_data):
    encoded_data = image_data.split(",")[1]
    nparr = np.frombuffer(base64.b64decode(encoded_data), np.uint8)
    return cv2.imdecode(nparr, cv2.IMREAD_COLOR)

# Dictionary to store the latest frame
frame_holder = {"image": None}

# Function to receive frames from JavaScript
def captureFrame(image_data):
    frame_holder["image"] = decode_image(image_data)

# Register the function to receive frames
from google.colab import output
output.register_callback('notebook.captureFrame', captureFrame)

from ultralytics import YOLO
import easyocr
import pyttsx3
from google.colab.patches import cv2_imshow
import time

# Load YOLO Model
yolo_model = YOLO("yolov8n.pt")

# Load OCR for text recognition
ocr_reader = easyocr.Reader(["en"])

# Initialize Text-to-Speech
engine = pyttsx3.init()
engine.setProperty("rate", 150)  # Adjust speed

# Activate Webcam in JavaScript
capture_webcam()

# Run Object Detection in Real-Time
while True:
    if frame_holder["image"] is not None:
        frame = frame_holder["image"].copy()

        # Perform object detection
        results = yolo_model(frame)

        for result in results:
            for box in result.boxes.xyxy:
                x1, y1, x2, y2 = map(int, box[:4])
                label = result.names[int(result.boxes.cls[0])]  # Object name

                # Extract text from detected object
                cropped = frame[y1:y2, x1:x2]
                text = ocr_reader.readtext(cropped)
                extracted_text = " ".join([t[1] for t in text]) if text else "No text detected"

                # Construct the spoken response
                response = f"I see a {label}. {extracted_text}."
                print(response)

                # Speak the response
                engine.say(response)
                engine.runAndWait()

                # Draw bounding box & label on the frame
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        # Show the frame in Colab
        cv2_imshow(frame)

    #time.sleep(0.1)  # Prevent CPU overload